{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-06T11:19:36-06:00"
    },
    {
      "path": "blog.html",
      "title": "Blog",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-06T11:19:38-06:00"
    },
    {
      "path": "finalproject.html",
      "title": "Final Project",
      "description": "Predicting test preparation using Support Vector Machines.\n",
      "author": [
        {
          "name": "Miriam Patrick",
          "url": {}
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\n\r\n\r\n\r\n.panelset{--panel-tab-font-family: inherit;}\r\n\r\nData Description\r\nThe data used in this project presents information about students’ grade performance and the variables that may affect it the performance. This information includes descriptive information about the student, their background, and their grades on 3 different exams (math, reading, and writing). The data set comes from the Kaggle dataset search database. The goal of this final project is to predict whether the student studied or not using support vector machines.\r\n\r\n                             vars    n  mean    sd median trimmed\r\ngender*                         1 1000  1.48  0.50      1    1.48\r\nrace.ethnicity*                 2 1000  3.17  1.16      3    3.20\r\nparental.level.of.education*    3 1000  3.49  1.83      3    3.48\r\nlunch*                          4 1000  1.65  0.48      2    1.68\r\ntest.preparation.course*        5 1000  1.64  0.48      2    1.68\r\nmath.score                      6 1000 66.09 15.16     66   66.38\r\nreading.score                   7 1000 69.17 14.60     70   69.50\r\nwriting.score                   8 1000 68.05 15.20     69   68.41\r\n                               mad min max range  skew kurtosis   se\r\ngender*                       0.00   1   2     1  0.07    -2.00 0.02\r\nrace.ethnicity*               1.48   1   5     4 -0.14    -0.75 0.04\r\nparental.level.of.education*  2.97   1   6     5 -0.03    -1.45 0.06\r\nlunch*                        0.00   1   2     1 -0.61    -1.64 0.02\r\ntest.preparation.course*      0.00   1   2     1 -0.59    -1.65 0.02\r\nmath.score                   14.83   0 100   100 -0.28     0.26 0.48\r\nreading.score                14.83  17 100    83 -0.26    -0.08 0.46\r\nwriting.score                16.31  10 100    90 -0.29    -0.05 0.48\r\n\r\nDescriptive Statistics\r\nThe tables above present the descriptive statistics for student performance dataset. Based on skewness, the data of all variables appears to be fairly symmetrical. The variables lunch and test.preparation.course appear to be moderately skewed. There are some low outliers for math, reading, and writing scores, which is reflected by a higher standard error(se).The standard deviation of the math, reading, and writing scores reflects a wider sample spread.\r\nSupport Vector Machines\r\nSupport Vector Machines is the machine learning model used to make predictions in this project. The algorithm is simple, but it can be an effective supervised machine learning approach to making predictions. Support Vector Machines works by using a hyper-plane to the data into distinct categories to make predictions. When establishing the boundaries for the hyper-plane, SVM chooses the hyperplane that creates the most space in between the data being categorized. SVM does this by trial and error, learning, and adjusting until the model optimizes.\r\n\r\n\r\n\r\nSVM Demonstration\r\n\r\n\r\n\r\n\r\n\r\nSVM Demonstration: The graph demonstrates how support vector machines makes predictions. More importantly, the graph demonstrates how tangled this data is. There is not a distinct separation between the data categories, which will make it harder to make predictions.\r\n\r\n\r\nResults\r\n\r\nConfusion Matrix and Statistics\r\n\r\n           Reference\r\nPrediction  completed none\r\n  completed        76   32\r\n  none             67  224\r\n                                          \r\n               Accuracy : 0.7519          \r\n                 95% CI : (0.7065, 0.7935)\r\n    No Information Rate : 0.6416          \r\n    P-Value [Acc > NIR] : 1.534e-06       \r\n                                          \r\n                  Kappa : 0.4297          \r\n                                          \r\n Mcnemar's Test P-Value : 0.0006329       \r\n                                          \r\n            Sensitivity : 0.5315          \r\n            Specificity : 0.8750          \r\n         Pos Pred Value : 0.7037          \r\n         Neg Pred Value : 0.7698          \r\n             Prevalence : 0.3584          \r\n         Detection Rate : 0.1905          \r\n   Detection Prevalence : 0.2707          \r\n      Balanced Accuracy : 0.7032          \r\n                                          \r\n       'Positive' Class : completed       \r\n                                          \r\n\r\nWe analyze the results of this model by viewing the confusion matrix above for predicting test preparation. An accuracy closer to 1 means that the model did well predicting correctly. The accuracy of this model is 0.7519. This means that the model did about 25% better than a coin flip at predicting test preparation. The dataset was unbalanced, but neither up-sampling nor down-sampling helped significantly with making predictions. The kappa for this model is .4297 so when running the model by chance, it performs decently. The model has 67 false negatives and a higher specificity, which is most likely due to the unbalanced dataset.\r\nROC, Gain, Lift\r\n\r\n\r\n\r\nDescription\r\nThe support Vector Machines algorithm generates a probabilistic classification. ROC curves, gain charts, and lift charts give users a visual way to compare estimators and analyze the performance of estimators. This is can be helpful for reference purposes. The graphs and descriptions of each are included in the next 3 tabs.\r\n\r\n\r\nROC curve\r\n\r\n\r\nCall:\r\nroc.default(response = factor(svmtestpred$test.preparation.course),     predictor = svmtestpred$completed)\r\n\r\nData: svmtestpred$completed in 143 controls (factor(svmtestpred$test.preparation.course) completed) > 256 cases (factor(svmtestpred$test.preparation.course) none).\r\nArea under the curve: 0.8081\r\n\r\n\r\n\r\nThe above plots present the ROC curve. This plot gives a way to visual analyze the performance of the estimators in the model. The diagonal line demonstrates a 50/50 chance of prediction correctly. The roc curve for this model presents a visual that validates that the model performs 25% better than a coin flip.\r\n\r\n\r\n\r\nGain Chart\r\n\r\n\r\n\r\n\r\nGain and lift charts provide a visual description of estimator performance that allows the user to use the information to optimally target specific goals. They can be used to analyze performance and evaluate/compare estimators. The visualization effect is important because a lot of imformation can be communicated in a way that is user friendly.\r\n\r\n\r\n\r\nLift Chart\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-06T11:19:57-06:00"
    },
    {
      "path": "index-delete.html",
      "title": "mfeo",
      "description": "Welcome to the website. I hope you enjoy it!\n",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-06T11:19:59-06:00"
    },
    {
      "path": "index.html",
      "title": "Miriam Patrick",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          Miriam Patrick\r\n          \r\n          \r\n          Home\r\n          Blog\r\n          \r\n          \r\n          About\r\n           \r\n          ▾\r\n          \r\n          \r\n          Resume\r\n          \r\n          \r\n          \r\n          \r\n          Projects\r\n           \r\n          ▾\r\n          \r\n          \r\n          Rsquared\r\n          KNN\r\n          Final Project\r\n          \r\n          \r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              Miriam Patrick\r\n            \r\n            \r\n              \r\n                \r\n                    \r\n                      \r\n                        LinkedIn\r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                        GitHub\r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                        Email\r\n                      \r\n                    \r\n                  \r\n                                  \r\n            \r\n          \r\n        \r\n        \r\n        \r\n          \r\n            I am currently a Graduate Assistant at Mississippi State University in Starkville, MS. I am working on my masters degree in Professional Accountancy with a minor in Data Analytics. I enjoy taking walks in the park and going fishing. I also play the keyboard for church in my spare time.\r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              Miriam Patrick\r\n            \r\n            \r\n              \r\n                \r\n                                    \r\n                    \r\n                      LinkedIn\r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      GitHub\r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      Email\r\n                    \r\n                  \r\n                                  \r\n              \r\n            \r\n            \r\n              I am currently a Graduate Assistant at Mississippi State University in Starkville, MS. I am working on my masters degree in Professional Accountancy with a minor in Data Analytics. I enjoy taking walks in the park and going fishing. I also play the keyboard for church in my spare time.\r\n            \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    ",
      "last_modified": "2021-12-06T11:19:59-06:00"
    },
    {
      "path": "KNN.html",
      "title": "KNN",
      "description": "Explanation of K-nearest neighbor\n",
      "author": [
        {
          "name": "Miriam Patrick",
          "url": {}
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\n\r\n\r\nKNN Model Description\r\nK-nearest Neighbor is a Machine Learning model that makes predictions based on the classification of the data points nearest to the data point being predicted. For example, the prediction of gender would be based on the gender of the points nearest to the point being used for prediction. The model assumes that points of similar values share similar characteristics and uses this assumption to make predictions. The area determined to be “nearest” is adjusted through trial and error until the model maximizes the number of correct predictions. The graph below helps provide a demonstration of this concept.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nThe graph demonstrates how the model uses points within proximity to make predictions for target variables. Based on the knn model, the red dot will be classified as Versicolor because the closest surrounding dots are classified as Versicolor.\r\n\r\nProcess\r\n\r\n\r\n    #set the seed :)\r\n    set.seed(1)\r\n    #lets split the data 60/40\r\n    library(caret)\r\n    trainIndex.6 <- createDataPartition(iris$Species, p = .6, list = FALSE, times = 1)\r\n\r\n    #grab the data\r\n    irisTrain.6 <- iris[ trainIndex.6,]\r\n    irisTest.6  <- iris[-trainIndex.6,]\r\n\r\n    preProcValues.6 <- preProcess(irisTrain.6, method = c(\"center\", \"scale\"))\r\n\r\n    trainTransformed.6 <- predict(preProcValues.6, irisTrain.6)\r\n\r\n    preProcValues.6 <- preProcess(irisTest.6, method = c(\"center\", \"scale\"))\r\n    testTransformed.6 <- predict(preProcValues.6, irisTest.6)\r\n\r\n    #fit knn\r\n    knn_fit.6<-train(Species~.,\r\n                   data=trainTransformed.6,\r\n                   method=\"knn\",\r\n                   tuneGrid=data.frame(k=5))\r\n\r\n    knn_fit.6\r\n\r\n    #predict on the test set\r\n    knn_pred.6<-predict(knn_fit.6,testTransformed.6)\r\n\r\n    #confusion matrix\r\n    confusionMatrix(knn_pred.6,testTransformed.6$Species)\r\n\r\n\r\n\r\nThe process of running this model includes partitioning the iris data into a training and a testing set. The knn model uses the training set to learn the tendencies of the data and establish boundaries for making flower species predictions. The data is then scaled and centered to help the algorithm function properly by normalizing the data. The model is run on the training data to allow the algorithm to optimize itself, and the predictions are made based on the parameters that yield the best results.\r\nResults\r\n\r\nConfusion Matrix and Statistics\r\n\r\n            Reference\r\nPrediction   setosa versicolor virginica\r\n  setosa         20          0         0\r\n  versicolor      0         18         1\r\n  virginica       0          2        19\r\n\r\nOverall Statistics\r\n                                          \r\n               Accuracy : 0.95            \r\n                 95% CI : (0.8608, 0.9896)\r\n    No Information Rate : 0.3333          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.925           \r\n                                          \r\n Mcnemar's Test P-Value : NA              \r\n\r\nStatistics by Class:\r\n\r\n                     Class: setosa Class: versicolor Class: virginica\r\nSensitivity                 1.0000            0.9000           0.9500\r\nSpecificity                 1.0000            0.9750           0.9500\r\nPos Pred Value              1.0000            0.9474           0.9048\r\nNeg Pred Value              1.0000            0.9512           0.9744\r\nPrevalence                  0.3333            0.3333           0.3333\r\nDetection Rate              0.3333            0.3000           0.3167\r\nDetection Prevalence        0.3333            0.3167           0.3500\r\nBalanced Accuracy           1.0000            0.9375           0.9500\r\n\r\nWe can analyze the results of this model by viewing the confusion matrix above for predicting flower species. Accuracy is a measure that evaluates the model’s performance by dividing the number of correct predictions by the total predictions. An accuracy closer to 1 means that the model did well predicting correctly. The accuracy of this model is 0.95. The model incorrectly predicted 3 out of 60 predictions, which is good. The kappa for this model is .925, so when running the model by chance, it performs well.\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-06T11:20:06-06:00"
    },
    {
      "path": "resume_website.html",
      "title": "Resume",
      "description": "\"Curriculum vitae\"\n",
      "author": [
        {
          "name": "Miriam Patrick",
          "url": {}
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\nEDUCATION\r\nMississippi State University–Adkerson School of Accountancy, Starkville, MS\r\nMaster of Professional Accountancy- Expected Completion Spring 2022\r\nBachelor of Accounting-Completed Spring 2021\r\nEast Central Community College, Decatur, MS\r\nAssociate in Liberal Arts with Business Concentration-Completed Spring 2019\r\nOverall GPA: 4.0\r\nWORK EXPERIENCE\r\nLibrary Assistant Summer 2019\r\nForest Public Library\r\nForest, MS 39074\r\nHelped customers access and navigate computers: Internet, Microsoft Word, etc.\r\nServiced personally up to 100 customers daily.\r\nAided in the set-up 5 summer reading programs\r\nHelped set up a community “Meet the Candidates” program that over 60 people attended\r\nPerformed transactions on the CMRLS library database.\r\n\r\nOffice Assistant Summer 2017\r\nScott County Solid Waste Office\r\nForest, MS 39074\r\nTyped over 20 letters concerning solid waste accounts and addresses\r\nHelped create over 20 new addresses.\r\nBalanced the cash drawer.\r\nServiced personally approx. 50 or more customers daily.\r\nRecorded approx. 60 payments manually daily.\r\n\r\nHONORS\r\nMississippi State University\r\nSCREP chair of MSU’s chapter of National Association of Black Accountants(2021-21)\r\nGraduate Assistant for MSU Adkerson School of Accountancy\r\nEast Central Community College\r\nMember of Phi Theta Kappa(2017-19)\r\nMusician for ECCC Gospel Choir\r\nSKILLS\r\nProficient in Microsoft Word, Excel, and Powerpoint\r\nFamiliar with R-Studio, RMarkdown, Tableau, ACL, and IDEA\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-06T11:20:09-06:00"
    },
    {
      "path": "Rsquared.html",
      "title": "Rsquared",
      "description": "An short discussion of a downfall of R-squared\n",
      "author": [
        {
          "name": "Miriam Patrick",
          "url": {}
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\nR-squared says nothing about prediction error, even with variance exactly the same, and no change in the coefficients. R-squared can be anywhere between 0 and 1 just by changing the range of X. Because R-squared can be swayed in this way, the results of experiments based on r-squared can be manipulated to support a hypothesis. The manipulation can mislead readers into accepting unsupported hypotheses or conclusions. R-squared does not truly measure goodness of fit. Most people are never think critically of R-squared because it was taught as being a great measure in statistic or another related course. Changing the range of x sequence of numbers such as (1-10) vs (0.1-1) can change R-squared. Knowing this, more critical thinking should be applied to research papers that flaunt a high R-squared.\r\nTo give a visual representation of the issue, r-squared will be presented for two ranges of numbers. The ranges are different by a multiple of 10.\r\n\r\nR-squared of first range:\r\n\r\n\r\n[1] 0.9383379\r\n\r\nNow we will repeat the code, but this time with the second range of x. Everything else is left the same.\r\n\r\nR-squared of second range:\r\n\r\n\r\n[1] 0.1502448\r\n\r\nR-squared changes significantly from .9383379 to .1502448 just because of the change in range. This is a drastic change for something that should not have such a significant effect.The metric should reflect the goodness of fit, and goodness of fit should be altered by range.\r\nAlternatives\r\nThere are several alternatives to R-squared that can act are as better metric. One example would be mean squared error. Mean squared error is the average of the squares of error. Unlike R-squared, MSE is not swayed by range. It measures estimator quality by assessing the error.The smaller the MSE the better.\r\n\r\nMean Squared Error first\r\n\r\n\r\n[1] 0.6468052\r\n\r\n\r\nMean Squared Error second\r\n\r\n\r\n[1] 0.6468052\r\n\r\nAs show in the results, we’re better off using Mean Square Error (MSE) as a measure of prediction error.\r\nAlthough it is not demonstrated, root mean squared error is another measure that is a good alternative to r-squared.\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-06T11:20:12-06:00"
    },
    {
      "path": "tobi.html",
      "title": "Tobi Burns",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          Miriam Patrick\r\n          \r\n          \r\n          Home\r\n          Blog\r\n          \r\n          \r\n          About\r\n           \r\n          ▾\r\n          \r\n          \r\n          Resume\r\n          \r\n          \r\n          \r\n          \r\n          Projects\r\n           \r\n          ▾\r\n          \r\n          \r\n          Rsquared\r\n          KNN\r\n          Final Project\r\n          \r\n          \r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            Tobi Burns\r\n          \r\n          \r\n            \r\n              I am currently a Graduate Assistant at Mississippi State University in Starkville, MS. I am working on my masters degree in Professional Accountancy with a minor in Data Analytics. I enjoy taking walks in the park and going fishing. I also play the keyboard for church in my spare time.\r\n            \r\n            \r\n              I am currently a Graduate Assistant at Mississippi State University in Starkville, MS. I am working on my masters degree in Professional Accountancy with a minor in Data Analytics. I enjoy taking walks in the park and going fishing. I also play the keyboard for church in my spare time.\r\n            \r\n          \r\n\r\n          \r\n            \r\n              \r\n                  \r\n                    \r\n                      LinkedIn\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      Twitter\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      GitHub\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      Email\r\n                    \r\n                  \r\n                \r\n                              \r\n          \r\n\r\n          \r\n            \r\n              \r\n                                \r\n                  \r\n                    LinkedIn\r\n                  \r\n                \r\n                                \r\n                  \r\n                    Twitter\r\n                  \r\n                \r\n                                \r\n                  \r\n                    GitHub\r\n                  \r\n                \r\n                                \r\n                  \r\n                    Email\r\n                  \r\n                \r\n                              \r\n            \r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    ",
      "last_modified": "2021-12-06T11:20:13-06:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
